#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
    This module collect number of pages on a specific categorie, and all books url. 
    It creates an array with books url and passes it to getBookInfo module. 
"""

import argparse
import requests
import getBookInfo
import re

from bs4 import BeautifulSoup, SoupStrainer





def extract_category_name(url):
    """This function extract category name from an URL
    params:
        ulr (str): book's URL
    return : 
        category_name (str) : categorys name
        """
    category_name = url.replace('http://books.toscrape.com/catalogue/category/books/', '').replace('/index.html', '').replace('_', '')
    category_name = category_name.replace('https://books.toscrape.com/catalogue/category/books/', '')
    category_name = re.sub(r'[0-9]+', '', category_name)
    return category_name


def getBooksUrlOnAPage(url):
    """Return an array of all books url for a category.
    params :
        url (str) : categories url
    return : 
        array_books_url (array): list of books url in a category 
    """
    response = requests.get(url)
    only_section = SoupStrainer('section')
    soup = BeautifulSoup(response.content, "lxml", parse_only=only_section)
    array_of_a = soup.select("h3 > a")
    array_books_url = []
    for el in array_of_a:
        array_books_url.append(el["href"].replace("../../..", "http://books.toscrape.com/catalogue"))
    return array_books_url


def getPagesUrl(base_url, num_page):
    """Return an array of all page_url for a category.
    params : 
        base_url (str) : url of the first page 
        num_page (int) : number of page in a category
    return :
        array_page_url (array) : an array that contains all page's url
    """
    array_page_url = []
    for num in range(num_page):
        if num == 0:
            array_page_url.append(base_url)
        else:    
            array_page_url.append(base_url.replace('index', 'page-'+ str(num+1) ))
    return array_page_url


def main(category_url, category_name="category"):
    """Main function of getCategoryInfo module 
        params : 
            category_url (string) : 
            category_name (string) : it is used for the .csv file's name
        output : csv in a folder called 'exports', the outpout is generated by the getBookInfo.py module
    """
    # send get request for a category
    response = requests.get(category_url)
    if response.ok:
        soup = BeautifulSoup(response.content, "lxml")

        #get the number of book on this category 
        book_number = int(soup.find("form", {"class":"form-horizontal"}).find("strong").text)

        # get the number of pages
        if book_number > 20 : 
            page_number = int(soup.find("li", {"class":"current"}).text.strip()[-1])
        else :
            page_number = 1

        # get an array of the pages urls 
        array_page_url = getPagesUrl(category_url, page_number)

        # get all books urls of this category
        array_books_url = []
        for el in array_page_url:
            page_book_list = getBooksUrlOnAPage(el)
            array_books_url.extend(page_book_list)

    else :
        response.raise_for_status()

    #little check 
    if len(array_books_url) == book_number:
        print("Scrapping en cours de la cat√©gorie : " + category_name)
        #send to getBookInfo module
        getBookInfo.main(array_books_url, category_name)
    else : 
        print("Number of books url not corresponding to number of books")


   
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("url", help="Enter a valid category url")
    args = parser.parse_args()

    try:
        main(args.url, extract_category_name(args.url))
    except :
        print("Error : add a valid categorie_page_url as an argument")


# http://books.toscrape.com/catalogue/category/books/sequential-art_5/page_2.html

# http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html
# print(len(array_books_url))